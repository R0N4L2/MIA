{"cells":[{"cell_type":"markdown","metadata":{"id":"YWDHtEcZ-_fq"},"source":["Pontificia Universidad Católica de Chile \n","\n","Instituto de Ingeniería Matemática y Computacional \n","\n","Magister en Inteligencia Artificial - MIA \n","\n","Tarea 2 \n","\n","Fundamentos Matemáticos para la Inteligencia Artif{icial IMT3850 2022 \n","\n","Prof. Manuel A. Sánchez \n","\n","Mayo 2022 \n","\n","Alumno: Ronald Castillo Capino\n","\n","Preguntas "]},{"cell_type":"markdown","metadata":{"id":"rs-M5Wro_Cam"},"source":["1. (10 puntos) __Variables aleatorias__.\n","\n","Muestre que si X e Y son variables aleatorias independientes, entonces: \n","\n","$Var[X + Y ] = Var[X] + Var[Y ]$ "]},{"cell_type":"markdown","metadata":{"id":"Uwwr5tJN_O_W"},"source":["Por definicion de $Var$, podemos obtener que:\n","\n","$$Var[X+Y]=\\mathbb{E}[(X+Y-\\mathbb{E}[(X+Y)])^2]$$\n","$$→Var[X+Y]=\\mathbb{E}[(X-\\mathbb{E}[X]+Y-\\mathbb{E}[Y])^2]$$\n","$$→Var[X+Y]=\\mathbb{E}[(X-\\mathbb{E}[X])^2+2(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])+(Y-\\mathbb{E}[Y])^2]$$\n","$$→Var[X+Y]=\\mathbb{E}[(X-\\mathbb{E}[X])^2]+2\\mathbb{E}[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])]+\\mathbb{E}[(Y-\\mathbb{E}[Y])^2]$$\n","\n","Por definicion $\\mathbb{E}[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])]=Cov(X,Y)$, entonces se tiene:\n","\n","$$→Var[X+Y]=Var[X]+2Cov(X,Y)+Var[Y]$$\n","\n","Como las variables X, Y son independientes, lo que implica que $Cov(X,Y)=0$, por lo tanto se obtiene finalmente que:\n","$$→Var[X+Y]=Var[X]+Var[Y]  \\square$$"]},{"cell_type":"markdown","metadata":{"id":"7XaTgb6ECMyw"},"source":["2. (20 puntos) __Algoritmo Random Quicksort.__ \n","\n","En clases observamos que el número esperado de comparaciones realizadas por el algoritmo Quicksort Aleatorio es de 2nln(n) + O(n), donde n es el largo de la lista S. El objetivo es testear este resultado. Para esto: \n","\n","a) Programe el algoritmo Quicksort con pivot aleatorio presentado en clases para ordenar de forma ascendente una lista S de números reales distintos. Corrobore que su algoritmo funciona mostrando la lista ordenada S = [0, 5, 4, 1, 7, 6, 3, 2, 8, 9]. "]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1652890321018,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"},"user_tz":300},"id":"w8748_MWcmrO","outputId":"811aa107-8b36-4b7e-81d8-4589e5845dda"},"outputs":[{"output_type":"stream","name":"stdout","text":["lista a probar: [0, 5, 4, 1, 7, 6, 3, 2, 8, 9]\n","lista resultado quicksort aleatorio: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"]}],"source":["import random\n","def quicksort(S):\n","  if len(S)>1:\n","    x=random.sample(S,1)\n","    S1=list(filter(lambda y:x[0]>y,S))\n","    S2=list(filter(lambda y:x[0]<y,S))\n","    S1,cont1=quicksort(S1)\n","    S2,cont2=quicksort(S2)\n","    cont=cont1+cont2+len(S)\n","    return [S1+x+S2,cont]\n","  else:\n","    return [S,len(S)]\n","\n","#lista a probar:\n","S = [0, 5, 4, 1, 7, 6, 3, 2, 8, 9]\n","print(\"lista a probar:\",S)\n","#resultado:\n","Z,_=quicksort(S)\n","print(\"lista resultado quicksort aleatorio:\",Z)"]},{"cell_type":"markdown","metadata":{"id":"zBE7-Mtkcm_s"},"source":["b) Para largo de lista n fijo, obtenga lista aleatorias y aplique el algoritmo a cada una de ellas calculando el numero de comparaciones realizadas en el algoritmo. Calcule el promedio de estas para n fijo."]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1652890323212,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"},"user_tz":300},"id":"CcxLMw8F-3_y","outputId":"439a4690-8ed9-4f15-a93a-a92827ad8779"},"outputs":[{"output_type":"stream","name":"stdout","text":["el promedio de las listas aleatorias de tamaño 100 es:745.64\n"]}],"source":["def comp_quicksort_n(n):\n","  X=random.sample(range(n**2),n)\n","  _,aux=quicksort(X)\n","  return aux\n","\n","n=100\n","p=100\n","avg=list(map(comp_quicksort_n,[n]*p))\n","print(f\"el promedio de las listas aleatorias de tamaño {n} es:{sum(avg)/p}\")"]},{"cell_type":"markdown","metadata":{"id":"yzxeh71xcuRV"},"source":["c) Repite el procedimiento anterior para n = [100, 200, 300, ..., 5000] y grafique n vs. el promedio de comparaciones para cada n. Ademas grafique las curvas correspondientes a $y=2nln(n)$ y $y=2n$. "]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":104380,"status":"ok","timestamp":1652890428698,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"},"user_tz":300},"id":"bbp1yeH2cuj3","outputId":"2d121025-bc97-47d4-8876-0d7b29036347"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import pandas as pd\n","p=100\n","L=pd.DataFrame(map(lambda n:(n,sum(map(comp_quicksort_n,[n]*p))/p),range(100,5100,100)),columns=['size','average'])\n","L['curva1']=np.log(L['size'])*L['size']*2\n","L['curva2']=L['size']*2\n","\n","import matplotlib.pyplot as plt\n","plt.plot(L['size'],L['average'],'o--',color='green',label='quicksort average')\n","plt.plot(L['size'],L['curva1'],'*--',color='blue',label='2*n*ln(n)')\n","plt.plot(L['size'],L['curva2'],'+--',color='red',label='2*n')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"YEYaN3hxc2Lc"},"source":["d) Explique porque los resultados del experimento corroboran los resultados teóricos."]},{"cell_type":"markdown","source":["Como se puede ver en la grafica anterior, en promedio la cantidad de comparaciones para el __Quick Sort Aleatorio__, es casi un poquito menor que $2n\\ln(n)$, por lo que se espera un valor cercano a lo esperado por el _teorema_. \n","\n","Este __Teorema__ dice, que si la forma de escojer aleatoriamente un valor de pivote, es de forma independiete y uniforme discreta entre todos los elementos de la lista. Entonces el numero esperado de comparaciones por el algoritmo es de la forma $2n\\ln(n)+O(n)$."],"metadata":{"id":"tbIi-H-7eIi4"}},{"cell_type":"markdown","metadata":{"id":"xk-UHHb9CY6P"},"source":["3. (10 puntos) __Convexidad__ \n","\n","Sea $f:\\mathbb{R}^d→\\mathbb{R}$ una función es diferenciable. Prube que f es una función convexa si y sólo si se satisface $f(y) ≥ f(x) + ∇f(x)^T(y − x)$ \n","para todo x, y en el dominio de f. "]},{"cell_type":"markdown","metadata":{"id":"cB76X49aCufP"},"source":["Como f es convexa, entonces se tiene que:\n","$$f(\\alpha y+ (1-\\alpha)x)\\le \\alpha f(y)+(1-\\alpha)f(x), \\forall \\alpha \\in [0,1]$$\n","$$\\rightarrow f(x+\\alpha (y-x))\\le f(x) +\\alpha (f(y)-f(x)), \\forall \\alpha \\in [0,1]$$\n","$$\\rightarrow f(x+\\alpha (y-x))-f(x)\\le \\alpha (f(y)-f(x)), \\forall \\alpha \\in [0,1]$$\n","$$\\rightarrow \\frac{f(x+\\alpha (y-x))-f(x)}{\\alpha} \\le f(y)-f(x), \\forall \\alpha \\in [0,1]$$\n","Como $\\alpha$ puede ser 0 tambien y la funcion es diferenciable, entonces podemos hacer $\\alpha\\rightarrow0$, con lo que quedaria:\n","\n","$$Lim_{\\alpha\\rightarrow0}\\frac{f(x+\\alpha(y-x))-f(x)}{\\alpha}=\\frac{df(x+\\alpha (y-x))}{d\\alpha}|_{\\alpha=0}=∇f(x)^T(y-x)$$\n","\n","Por lo tanto, se tiene que:\n","\n","$$\\rightarrow ∇f(x)^T(y-x) \\le f(y)-f(x)$$\n","$$\\rightarrow ∇f(x)^T(y-x)+f(x) \\le f(y)\\square$$\n"]},{"cell_type":"markdown","metadata":{"id":"hAbnMeoXCu2e"},"source":["4. (20 puntos) __Descenso del gradiente__\n","\n","Considere el set de datos datos_lineales.csv que contiene pares de puntos $(x, y) \\in \\mathbb{R}^2$. Se busca resolver el problema: \n"," \n","\n","$$mín_{\\theta \\in \\mathbb{R}^2} \\frac{1}{2N} \\|X\\theta − y\\|^2_2, X \\in \\mathbb{R}^{N×2}, y \\in \\mathbb{R}^N$$ \n","\n","donde $θ$ son los coeficientes del polinomio lineal que mejor ajusta la matriz de datos X con los valores y.\n","\n","a) Programe el algoritmo de descenso de gradiente para resolver este problema. Considere como parámetros de este algoritmo: __X, y, NITMAX, $\\gamma$__ donde __NITMAX__ es el máximo número de iteraciones y __$\\gamma$__ es la función tasa de aprendizaje."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Bz3TJ_yaepNi","executionInfo":{"status":"ok","timestamp":1652885207076,"user_tz":300,"elapsed":15,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"}}},"outputs":[],"source":["import numpy as np\n","def des_grad(X,y,gamma,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.shape[0]\n","  for i in range(NITMAX):\n","    theta-=gamma*np.matmul(np.transpose(X),(np.matmul(X,theta)-y))/N\n","    if np.linalg.norm(np.matmul(np.transpose(X),(np.matmul(X,theta)-y)))/N<tol:\n","      break\n","  return theta"]},{"cell_type":"code","source":["import pandas as pd\n","data=pd.read_csv('/content/drive/MyDrive/MIA/IMT3850 - Fundamentos Matemáticos para Inteligencia Artificial/Tarea 2/datos_lineales.csv')\n","X=data.x.values.reshape(-1,1)\n","#agregamos una columnas de 1, para calcular tambien el intercepto de la regresion lineal\n","X=np.concatenate([np.ones((X.shape[0],1)),X],axis=1)\n","y=data.y.values.reshape(-1,1)\n","#taza de aprendizaje fijo\n","gamma=.5\n","#numero maximo de iteraciones\n","NITMAX=10**5\n","print(\"El valor de theta es para el algoritmo de gradiente descendente:\")\n","print(des_grad(X,y,gamma,NITMAX))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbHCStyM5nAF","executionInfo":{"status":"ok","timestamp":1652885207510,"user_tz":300,"elapsed":444,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"}},"outputId":"3a5eb698-448d-4b79-c26d-d380019cf25b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["El valor de theta es para el algoritmo de gradiente descendente:\n","[[0.98833908]\n"," [2.94783585]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"3cZw1-xAeoSc"},"source":["\n","b) Programe el algoritmo de descenso de gradiente estocástico para resolver este problema. Considere como parámetros de este algoritmo: __X, y, NITMAX, $\\gamma$__ donde __NITMAX__ es el máximo número de iteraciones y __$\\gamma$__ es la función tasa de aprendizaje. "]},{"cell_type":"code","execution_count":17,"metadata":{"id":"_tWu738ACzYu","executionInfo":{"status":"ok","timestamp":1652885207511,"user_tz":300,"elapsed":5,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"}}},"outputs":[],"source":["import random\n","def des_grad_sto(X,y,gamma,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.shape[0]\n","  #El tamaño de la muestra de la data es √n\n","  size=int(N**.5)\n","  for i in range(NITMAX):\n","    pos=random.sample(range(N),size)\n","    X1=X[pos,:].reshape(size,-1)\n","    y1=y[pos,:].reshape(size,-1)\n","    theta1=theta-gamma*np.matmul(np.transpose(X1),(np.matmul(X1,theta)-y1))/N\n","    if np.linalg.norm(theta1-theta)<tol:\n","      break\n","    else:\n","      theta=theta1\n","  return theta"]},{"cell_type":"code","source":["X=data.x.values.reshape(-1,1)\n","#agregamos una columnas de 1, para calcular tambien el intercepto de la regresion lineal\n","X=np.concatenate([np.ones((X.shape[0],1)),X],axis=1)\n","y=data.y.values.reshape(-1,1)\n","#taza de aprendizaje fijo\n","gamma=.5\n","#numero maximo de iteraciones\n","NITMAX=10**5\n","print(\"El valor de theta es para el algoritmo de gradiente descendente estocastico:\")\n","print(des_grad_sto(X,y,gamma,NITMAX))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DT7Iv1G3_9C-","executionInfo":{"status":"ok","timestamp":1652885213298,"user_tz":300,"elapsed":5790,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"}},"outputId":"9a8155cb-0d06-4e23-994c-5be7c53457db"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["El valor de theta es para el algoritmo de gradiente descendente estocastico:\n","[[1.02956772]\n"," [2.93701793]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"SSoNXinfesYx"},"source":["c) Considere las siguientes tasas de aprendizaje: \n","$$γ(t) = γ_{clases}(t), \\hspace{1em} γ(t) = \\frac{1}{\\sqrt{t}}$$ \n","Donde $γ_{clases}$ es la heurística vista en clases. Para cada una ejecute 100 veces el algoritmo estocástico y reporte el promedio de los resultados. Compare estos sus resultados con los del algoritmo determinista con la tasa correspondiente. "]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Y8YmqtsKe2O7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652885906642,"user_tz":300,"elapsed":693348,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"}},"outputId":"42818485-9943-46af-e5ca-b4b3828c23f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["El valor de theta es para el algoritmo de gradiente descendente, con taza de aprendizaje backtraking:\n","[[0.98844028]\n"," [2.94775293]]\n","El valor de theta es para el algoritmo de gradiente descendente, con taza de aprendizaje  1/√t:\n","[[0.98844146]\n"," [2.94775196]]\n","El valor de theta es para el algoritmo de gradiente descendente estocastico, con taza de aprendizaje backtraking:\n","[[0.98891037]\n"," [2.95038902]]\n","El valor de theta es para el algoritmo de gradiente descendente estocastico, con taza de aprendizaje 1/√t:\n","[[1.30418993]\n"," [2.6879343 ]]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import random\n","#gamma calculado con metodo de backtraking\n","def backtrack(theta,X,y,N):\n","  dfx=np.matmul(np.transpose(X),(np.matmul(X,theta)-y))/N\n","  fx=np.linalg.norm(np.matmul(X,theta)-y)**2/(2*N)\n","  gamma,alpha, beta=[.5,.5,.9]  \n","  while np.linalg.norm(np.matmul(X,theta-gamma*dfx)-y)**2/(2*N)>fx-alpha*gamma*np.linalg.norm(dfx)**2:\n","      gamma*= beta\n","  return gamma\n","\n","#gradiente descendente con tamaño de paso de backtraking\n","def des_grad_backtraking(X,y,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.size\n","  for i in range(NITMAX):\n","    gamma=backtrack(theta,X,y,N)\n","    theta-=gamma*np.matmul(np.transpose(X),(np.matmul(X,theta)-y))/N\n","    if np.linalg.norm(np.matmul(np.transpose(X),(np.matmul(X,theta)-y)))/N<tol:\n","      break\n","  return theta\n","\n","#gradiente descendente estocastico con tamaño de paso de backtraking\n","def des_grad_stochastic_backtraking(X,y,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.shape[0]\n","  size=int(N**.5)\n","  for i in range(NITMAX):\n","    pos=random.sample(range(N),size)\n","    X1=X[pos,:].reshape(size,-1)\n","    y1=y[pos,:].reshape(size,-1)\n","    gamma=backtrack(theta,X1,y1,N)\n","    theta1=theta-gamma*np.matmul(np.transpose(X1),(np.matmul(X1,theta)-y1))/N\n","    if np.linalg.norm(theta1-theta)<tol:\n","      break\n","    else:\n","      theta=theta1\n","  return theta\n","\n","#gradiente descendente con tamaño de paso de la inversa de la raiz\n","def des_grad_frac_raiz(X,y,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.shape[0]\n","  for i in range(1,NITMAX+1):\n","    theta-=np.matmul(np.transpose(X),(np.matmul(X,theta)-y))/(i**.5*N)\n","    if np.linalg.norm(np.matmul(np.transpose(X),(np.matmul(X,theta)-y)))/N<tol:\n","      break\n","  return theta\n","\n","#gradiente descendente estocastico con tamaño de paso de la inversa de la raiz\n","def des_grad_stochastic_frac_raiz(X,y,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.shape[0]\n","  #El tamaño de la muestra de la data es √n\n","  size=int(N**.5)\n","  for i in range(1,NITMAX+1):\n","    pos=random.sample(range(N),size)\n","    X1=X[pos,:].reshape(size,-1)\n","    y1=y[pos,:].reshape(size,-1)\n","    theta1=theta-np.matmul(np.transpose(X1),(np.matmul(X1,theta)-y1))/(i**.5*N)\n","    if np.linalg.norm(theta1-theta)<tol:\n","      break\n","    else:\n","      theta=theta1\n","  return theta\n","\n","\n","data=pd.read_csv('/content/drive/MyDrive/MIA/IMT3850 - Fundamentos Matemáticos para Inteligencia Artificial/Tarea 2/datos_lineales.csv')\n","X=data.x.values.reshape(-1,1)\n","#agregamos una columnas de 1, para calcular tambien el intercepto de la regresion lineal\n","X=np.concatenate([np.ones((X.shape[0],1)),X],axis=1)\n","y=data.y.values.reshape(-1,1)\n","#numero maximo de iteraciones\n","NITMAX=10**5\n","print(\"El valor de theta es para el algoritmo de gradiente descendente, con taza de aprendizaje backtraking:\")\n","print(des_grad_backtraking(X,y,NITMAX))\n","print(\"El valor de theta es para el algoritmo de gradiente descendente, con taza de aprendizaje  1/√t:\")\n","print(des_grad_frac_raiz(X,y,NITMAX))\n","sgd_bt=[]\n","sgd_raiz=[]\n","for j in range(100):\n","  sgd_bt+=[des_grad_stochastic_backtraking(X,y,NITMAX)]\n","  sgd_raiz+=[des_grad_stochastic_frac_raiz(X,y,NITMAX)]\n","\n","print(\"El valor de theta es para el algoritmo de gradiente descendente estocastico, con taza de aprendizaje backtraking:\")\n","print(np.mean(sgd_bt,axis=0))\n","print(\"El valor de theta es para el algoritmo de gradiente descendente estocastico, con taza de aprendizaje 1/√t:\")\n","print(np.mean(sgd_raiz,axis=0))"]},{"cell_type":"markdown","source":["Como se puede ver los resultados anteriores, la taza de aprendizaje para el gradiente descendente(GD), no importa mucho. Ya que son relativamente similares, por lo que si se ocupa una taza de aprendizaje _\"buena\"_ siempre va a converger con el metodo de gradiente descendente(GD). En cambio para el metodo del gradiente descendetnte estocastico (SGD), se puede ver que el metodo de tamaño de pasos de la forma __backtraking__ se aproxima mucho mejor al GD que el otro metodo de taza de aprendizaje, por lo que se podria concluir que el metodo SGD en conjunto con backtraking, se podria ocupar para un modelo, donde se necesita mucha data para el aprendizaje de la maquina, y este seria mejor que el GD.  "],"metadata":{"id":"QgC8dcR7t6ua"}},{"cell_type":"markdown","metadata":{"id":"pJg267eue1sT"},"source":["\n","d) Repita el item anterior pero ahora con el set de datos datos_cuadraticos.csv. Notar que ahora $X ∈ \\mathbb{R}^{N×3}$ y que $θ ∈ \\mathbb{R}^3$. "]},{"cell_type":"code","execution_count":20,"metadata":{"id":"x8Qa8LX4etMK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652886770113,"user_tz":300,"elapsed":863483,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"}},"outputId":"a75252d2-17ca-4a3f-858b-d31580935983"},"outputs":[{"output_type":"stream","name":"stdout","text":["El valor de theta es para el algoritmo de gradiente descendente, con taza de aprendizaje backtraking:\n","[[ 0.97960596]\n"," [-1.9682466 ]\n"," [ 0.9889967 ]]\n","El valor de theta es para el algoritmo de gradiente descendente, con taza de aprendizaje  1/√t:\n","[[ 0.97948597]\n"," [-1.9679338 ]\n"," [ 0.98885289]]\n","El valor de theta es para el algoritmo de gradiente descendente estocastico, con taza de aprendizaje backtraking:\n","[[ 0.97943468]\n"," [-1.96837072]\n"," [ 0.98926943]]\n","El valor de theta es para el algoritmo de gradiente descendente estocastico, con taza de aprendizaje 1/√t:\n","[[ 0.3369445 ]\n"," [-0.30916454]\n"," [ 0.22314387]]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import random\n","\n","def backtrack(theta,X,y,N):\n","  dfx=np.matmul(np.transpose(X),(np.matmul(X,theta)-y))/N\n","  fx=np.linalg.norm(np.matmul(X,theta)-y)**2/(2*N)\n","  gamma,alpha, beta=[.5,.5,.9]  \n","  while np.linalg.norm(np.matmul(X,theta-gamma*dfx)-y)**2/(2*N)>fx-alpha*gamma*np.linalg.norm(dfx)**2:\n","      gamma*= beta\n","  return gamma\n","  \n","def des_grad_backtraking(X,y,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.shape[0]\n","  for i in range(NITMAX):\n","    gamma=backtrack(theta,X,y,N)\n","    theta-=gamma*np.matmul(np.transpose(X),(np.matmul(X,theta)-y))/N\n","    if np.linalg.norm(np.matmul(np.transpose(X),(np.matmul(X,theta)-y)))/N<tol:\n","      break\n","  return theta\n","\n","def des_grad_stochastic_backtraking(X,y,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.shape[0]\n","  #El tamaño de la muestra de la data es √n\n","  size=int(N**.5)\n","  for i in range(NITMAX):\n","    pos=random.sample(range(N),size)\n","    X1=X[pos,:].reshape(size,-1)\n","    y1=y[pos,:].reshape(size,-1)\n","    gamma=backtrack(theta,X1,y1,N)\n","    theta1=theta-gamma*np.matmul(np.transpose(X1),(np.matmul(X1,theta)-y1))/N\n","    if np.linalg.norm(theta1-theta)<tol:\n","      break\n","    else:\n","      theta=theta1\n","  return theta\n","\n","def des_grad_frac_raiz(X,y,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.shape[0]\n","  for i in range(1,NITMAX+1):\n","    theta-=np.matmul(np.transpose(X),(np.matmul(X,theta)-y))/(N*i**.5)\n","    if np.linalg.norm(np.matmul(np.transpose(X),(np.matmul(X,theta)-y)))/N<tol:\n","      break\n","  return theta\n","\n","def des_grad_stochastic_frac_raiz(X,y,NITMAX):\n","  theta=np.random.normal(0,1,size=(X.shape[1],y.shape[1]))\n","  tol=10**-5\n","  N=y.shape[0]\n","  #El tamaño de la muestra de la data es √n\n","  size=int(N**.5)\n","  for i in range(1,NITMAX+1):\n","    pos=random.sample(range(N),size)\n","    X1=X[pos,:].reshape(size,-1)\n","    y1=y[pos,:].reshape(size,-1)\n","    theta1=theta-np.matmul(np.transpose(X1),(np.matmul(X1,theta)-y1))/(N*i**.5)\n","    if np.linalg.norm(theta1-theta)<tol:\n","      break\n","    else:\n","      theta=theta1\n","  return theta\n","\n","\n","data=pd.read_csv('/content/drive/MyDrive/MIA/IMT3850 - Fundamentos Matemáticos para Inteligencia Artificial/Tarea 2/datos_cuadraticos.csv')\n","X=data.x.values.reshape(-1,1)\n","#agregamos una columnas de 1, para calcular tambien el intercepto y elemento cuadratico de la regresion cuadratica\n","X=np.concatenate([np.ones((X.shape[0],1)),X,X**2],axis=1)\n","y=data.y.values.reshape(-1,1)\n","#numero maximo de iteraciones\n","NITMAX=10**5\n","print(\"El valor de theta es para el algoritmo de gradiente descendente, con taza de aprendizaje backtraking:\")\n","print(des_grad_backtraking(X,y,NITMAX))\n","print(\"El valor de theta es para el algoritmo de gradiente descendente, con taza de aprendizaje  1/√t:\")\n","print(des_grad_frac_raiz(X,y,NITMAX))\n","sgd_bt=[]\n","sgd_raiz=[]\n","for j in range(100):\n","  sgd_bt+=[des_grad_stochastic_backtraking(X,y,NITMAX)]\n","  sgd_raiz+=[des_grad_stochastic_frac_raiz(X,y,NITMAX)]\n","\n","print(\"El valor de theta es para el algoritmo de gradiente descendente estocastico, con taza de aprendizaje backtraking:\")\n","print(np.mean(sgd_bt,axis=0))\n","print(\"El valor de theta es para el algoritmo de gradiente descendente estocastico, con taza de aprendizaje 1/√t:\")\n","print(np.mean(sgd_raiz,axis=0))"]},{"cell_type":"markdown","source":["Al igual que en el caso anterior, el __SGD__ con taza de aprendizaje de la forma $\\frac{1}{\\sqrt{t}}$, es muy mal metodo para encontrar el optimo, _vs_ el de __backtraking__, que los valores son similares a los de __GD__. "],"metadata":{"id":"C8xJlsI4xfWw"}},{"cell_type":"markdown","metadata":{"id":"dd0epQ5kCyxy"},"source":["5. (10 puntos) Bonus: __Algoritmo de mediana aleatoria__\n","\n","Programe el algoritmo mediana aleatoria visto en clases. Realice experiementos aleatorios y muestre evidencia de que el algoritmo calcula con éxito la mediana de una lista."]},{"cell_type":"code","source":["import random\n","import math \n","import numpy as np\n","import pandas as pd\n","#Ordenamiento de Quicksort con elementos repetidos\n","def quicksort(S):\n","  if len(S)>1:\n","    x=random.sample(S,1)\n","    S1=list(filter(lambda y:x[0]>y,S))\n","    S2=list(filter(lambda y:x[0]<y,S))\n","    S1,cont1=quicksort(S1)\n","    S2,cont2=quicksort(S2)\n","    cont=cont1+cont2+len(S)\n","    return [S1+x*S.count(x[0])+S2,cont]\n","  else:\n","    return [S,len(S)]\n","def media_aleatoria(S):\n","  n = len(S)\n","  #n tiene que ser mayor que 16, ya que n**(3/4)/2-n**(1/2)>0=>(factorizando por n**(1/2)) n**(1/4)/2-1>0=>n**(1/4)>2=>n>2**4=16 para que funcione el algoritmo\n","  if n>16:\n","    n34 = n**(3/4)\n","    n12 = n**(1/2)\n","    n1=int(math.ceil(n34))\n","    R = random.sample(S,n1)\n","    R, _ = quicksort(R)\n","    d = R[int(n34/2 - n12)]\n","    u = R[int(n34/2 + n12-1)]\n","    ld=sum(map(lambda x:x<d,S))\n","    lu=sum(map(lambda x:x>u,S))\n","    C=list(filter(lambda x:d<=x<=u,S))\n","    if ld > n/2 or lu > n/2:\n","      print(\"error\")\n","      return np.nan\n","    elif len(C) <= 4*n34:\n","      C, _ = quicksort(C)\n","      return C[n//2-ld+1]\n","    else:\n","      print(\"error\")\n","      return np.nan\n","  elif (n<=16) and (n>1):\n","    return media_aleatoria((16//n+1)*S)\n","  elif n==1:\n","    return S[0]\n","  else:\n","    print(\"no tiene elementos\")\n","\n","C=[]\n","for i in range(100):\n","  S=random.sample(range(1000),random.randint(10,100))\n","  C+=[pd.DataFrame({'algoritmo de la clase con orden quicksort':[media_aleatoria(S)],'mediana de numpy':[np.median(S)],'tamaño':[len(S)]})]\n","D=pd.concat(C,axis=0).reset_index(drop=True)\n","D"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"J3IOepm-73Dx","executionInfo":{"status":"ok","timestamp":1652890296870,"user_tz":300,"elapsed":475,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"}},"outputId":"020b2e13-44ff-44b5-ebf0-656852f83781"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    algoritmo de la clase con orden quicksort  mediana de numpy  tamaño\n","0                                         453             450.0      62\n","1                                         462             441.5      36\n","2                                         560             557.0      83\n","3                                         641             566.0      46\n","4                                         602             592.5      26\n","..                                        ...               ...     ...\n","95                                        584             553.5      24\n","96                                        528             510.0      65\n","97                                        458             450.5      64\n","98                                        539             515.5      94\n","99                                        490             463.0      15\n","\n","[100 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-b8e33d05-d8ad-452a-bce4-bb67690d2144\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>algoritmo de la clase con orden quicksort</th>\n","      <th>mediana de numpy</th>\n","      <th>tamaño</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>453</td>\n","      <td>450.0</td>\n","      <td>62</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>462</td>\n","      <td>441.5</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>560</td>\n","      <td>557.0</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>641</td>\n","      <td>566.0</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>602</td>\n","      <td>592.5</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>584</td>\n","      <td>553.5</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>528</td>\n","      <td>510.0</td>\n","      <td>65</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>458</td>\n","      <td>450.5</td>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>539</td>\n","      <td>515.5</td>\n","      <td>94</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>490</td>\n","      <td>463.0</td>\n","      <td>15</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8e33d05-d8ad-452a-bce4-bb67690d2144')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b8e33d05-d8ad-452a-bce4-bb67690d2144 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b8e33d05-d8ad-452a-bce4-bb67690d2144');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["Como se puede ver en la tabla anterior, el algoritmo de mediana aleatoria no encuentra exactamente siempre el valor de la mediana, ya que este se va reduciendo de el conjunto a un subconjunto de forma aleatoria. Pero si se acerca bastante al valor real. Se puede calcular su error absoluto el cual es:"],"metadata":{"id":"_hN0h3Tq_seU"}},{"cell_type":"code","source":["((D['algoritmo de la clase con orden quicksort']-D['mediana de numpy']).abs()/D['tamaño']).mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VX3hQMiB_r89","executionInfo":{"status":"ok","timestamp":1652890301004,"user_tz":300,"elapsed":173,"user":{"displayName":"Ronald Humberto Castillo Capino","userId":"08373628220422889224"}},"outputId":"a51f11a5-8d5e-4b9a-b28e-3fdaa8ded6b5"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0163863255987688"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["Por lo que en promedio tendria una MAE de no mas de 2."],"metadata":{"id":"WB2oDsWtBVge"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"Tarea 2-IMT3850-Ronald Castillo.ipynb","provenance":[],"mount_file_id":"1qGP1x7fxCofOxLOlMPac9xdRygN0Wx9P","authorship_tag":"ABX9TyOY/yqulw71RDWt4qOjqQjL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}